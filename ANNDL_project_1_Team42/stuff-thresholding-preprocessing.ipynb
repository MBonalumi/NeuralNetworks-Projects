{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Init","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/input/leaves\n!ls","metadata":{"execution":{"iopub.status.busy":"2021-11-18T22:58:11.346525Z","iopub.execute_input":"2021-11-18T22:58:11.346968Z","iopub.status.idle":"2021-11-18T22:58:12.137111Z","shell.execute_reply.started":"2021-11-18T22:58:11.346879Z","shell.execute_reply":"2021-11-18T22:58:12.135912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport os\nimport random\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\nfrom sklearn.metrics import confusion_matrix\nfrom PIL import Image\n\n\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2 as cv\n\ntfk = tf.keras\ntfkl = tf.keras.layers\nprint(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T22:58:13.261992Z","iopub.execute_input":"2021-11-18T22:58:13.263063Z","iopub.status.idle":"2021-11-18T22:58:20.813427Z","shell.execute_reply.started":"2021-11-18T22:58:13.263014Z","shell.execute_reply":"2021-11-18T22:58:20.812494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random seed for reproducibility\nseed = 42\n\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\ntf.random.set_seed(seed)\ntf.compat.v1.set_random_seed(seed)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T22:58:20.829663Z","iopub.execute_input":"2021-11-18T22:58:20.830977Z","iopub.status.idle":"2021-11-18T22:58:20.844064Z","shell.execute_reply.started":"2021-11-18T22:58:20.830936Z","shell.execute_reply":"2021-11-18T22:58:20.84318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataset folders \ndataset_dir = '/kaggle/input/leaves'\ntraining_dir = os.path.join(dataset_dir, 'training')","metadata":{"execution":{"iopub.status.busy":"2021-11-18T22:58:20.845714Z","iopub.execute_input":"2021-11-18T22:58:20.845976Z","iopub.status.idle":"2021-11-18T22:58:20.854707Z","shell.execute_reply.started":"2021-11-18T22:58:20.845947Z","shell.execute_reply":"2021-11-18T22:58:20.853652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Augmentation","metadata":{}},{"cell_type":"code","source":"aug_data_gen = ImageDataGenerator(rotation_range=30,\n                                  zoom_range=0.3,\n                                  horizontal_flip = True,\n                                  vertical_flip = True,\n                                  brightness_range = (0.7, 1.3),\n                                  fill_mode='reflect',\n                                  #COMMENTED BECAUSE GAP MAKES INVARIANT TO SHIFT\n                                  #width_shift_range = 30,     #maybe even more!!!\n                                  #height_shift_range = 30,\n                                  validation_split=0.2,\n                                  rescale=1/255.)\n\n#augmented\ntrain_gen = aug_data_gen.flow_from_directory(directory = training_dir,\n                                                 subset = 'training',\n                                                 target_size=(256,256),\n                                                 color_mode='rgb',\n                                                 classes=None,\n                                                 class_mode='categorical',\n                                                 batch_size=8,\n                                                 shuffle=True,\n                                                 seed=seed)\n\nvalid_gen = ImageDataGenerator(validation_split=0.2).flow_from_directory(directory = training_dir,\n                                                 subset = 'validation',\n                                                 target_size=(256,256),\n                                                 color_mode='rgb',\n                                                 classes=None,\n                                                 class_mode='categorical',\n                                                 batch_size=8,\n                                                 shuffle=False,\n                                                 seed=seed)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T22:58:34.80039Z","iopub.execute_input":"2021-11-18T22:58:34.800947Z","iopub.status.idle":"2021-11-18T22:58:37.105031Z","shell.execute_reply.started":"2021-11-18T22:58:34.8009Z","shell.execute_reply":"2021-11-18T22:58:37.104071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = (train_gen.class_indices)\ninv_labels = {v: k for k, v in labels.items()}\nprint(inv_labels)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T22:58:37.891371Z","iopub.execute_input":"2021-11-18T22:58:37.89165Z","iopub.status.idle":"2021-11-18T22:58:37.896756Z","shell.execute_reply.started":"2021-11-18T22:58:37.891621Z","shell.execute_reply":"2021-11-18T22:58:37.896076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(inv_labels[3])","metadata":{"execution":{"iopub.status.busy":"2021-11-17T17:41:03.262445Z","iopub.execute_input":"2021-11-17T17:41:03.262732Z","iopub.status.idle":"2021-11-17T17:41:03.290692Z","shell.execute_reply.started":"2021-11-17T17:41:03.262701Z","shell.execute_reply":"2021-11-17T17:41:03.289638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Visualization __from folder__","metadata":{}},{"cell_type":"code","source":"num_row = 2\nnum_col = 7\nfig, axes = plt.subplots(num_row, num_col, figsize=(8*num_row,num_col))\nfor i in range(num_row*num_col):\n  if i < (num_row*num_col):\n    class_dir = os.path.join(training_dir, inv_labels[i])\n    print(class_dir)\n    class_imgs = next(os.walk(class_dir))[2]\n    class_img = class_imgs[0]\n    print(os.path.join(class_dir, class_img))\n    img = Image.open(os.path.join(class_dir, class_img))\n#     img = train_gen.next()[0]   #from generator instead of from file\n    \n#     img[:,:,1] = 0\n    \n    ax = axes[i//num_col, i%num_col]\n    ax.imshow(np.array(img))\n    \n    ax.set_title('{}'.format(inv_labels[i]))\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-17T16:17:01.687529Z","iopub.execute_input":"2021-11-17T16:17:01.687797Z","iopub.status.idle":"2021-11-17T16:17:04.853735Z","shell.execute_reply.started":"2021-11-17T16:17:01.687768Z","shell.execute_reply":"2021-11-17T16:17:04.85292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tresholding","metadata":{}},{"cell_type":"code","source":"def preprocess(im):\n    im = im.astype('uint8')\n    \n    im_thresh = cv.cvtColor(im, cv.COLOR_BGR2GRAY)\n    im_thresh = cv.adaptiveThreshold(im_thresh,255,cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY,11,2)\n    \n#     threshold = 100\n#     im_thresh = im_thresh.point(lambda p: p > threshold and 255)\n    \n    im_thresh = 255-im_thresh\n    \n    im[:,:,0] = im_thresh\n    \n#     print(im.shape)\n    \n    res = im.astype('float64')\n    res /= 255\n    return res","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:00:04.775097Z","iopub.execute_input":"2021-11-18T23:00:04.775918Z","iopub.status.idle":"2021-11-18T23:00:04.782075Z","shell.execute_reply.started":"2021-11-18T23:00:04.775881Z","shell.execute_reply":"2021-11-18T23:00:04.781183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tresh_data_gen = ImageDataGenerator(validation_split=0.2,\n                                    #all other augmentation stuff: \n                                    preprocessing_function = preprocess,\n#                                     rescale=1/255.,       #rescale done after adaptive thresholding\n                                    dtype='uint8')\n\n#augmented\ntrain_gen2 = tresh_data_gen.flow_from_directory(directory = training_dir,\n                                                 subset = 'training',\n                                                 target_size=(256,256),\n                                                 color_mode='rgb',\n                                                 classes=None,\n                                                 class_mode='categorical',\n                                                 batch_size=8,\n                                                 shuffle=True,\n                                                 seed=seed)\n\nvalid_gen = ImageDataGenerator(validation_split=0.2).flow_from_directory(directory = training_dir,\n                                                 subset = 'validation',\n                                                 target_size=(256,256),\n                                                 color_mode='rgb',\n                                                 classes=None,\n                                                 class_mode='categorical',\n                                                 batch_size=8,\n                                                 shuffle=False,\n                                                 seed=seed)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:00:06.90682Z","iopub.execute_input":"2021-11-18T23:00:06.907204Z","iopub.status.idle":"2021-11-18T23:00:08.750141Z","shell.execute_reply.started":"2021-11-18T23:00:06.907172Z","shell.execute_reply":"2021-11-18T23:00:08.749018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generated = cv.resize(train_gen2.next(), (256,256), interpolation = cv.INTER_AREA)\ngenerated = train_gen2.next()\nidx = (train_gen2.batch_index - 1) * train_gen2.batch_size\nprint(train_gen2.filenames[idx : idx + train_gen2.batch_size])\n\nprint('-----------')\nprint(generated[0].shape)   #  (1,256,256,3)\n\nimg, label = generated\n\nprint(img.shape)   #  (1,256,256,3)\nplt.imshow(img[0], 'gray')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:01:05.617491Z","iopub.execute_input":"2021-11-18T23:01:05.617958Z","iopub.status.idle":"2021-11-18T23:01:05.965374Z","shell.execute_reply.started":"2021-11-18T23:01:05.617913Z","shell.execute_reply":"2021-11-18T23:01:05.964696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Visualization **from generator!!!**","metadata":{}},{"cell_type":"code","source":"num_row = 2\nnum_col = 7\nfig, axes = plt.subplots(num_row, num_col, figsize=(8*num_row,num_col))\n\n\nfor i in range(num_row*num_col):\n  if i < (num_row*num_col):\n    \n    img_batch, label = train_gen2.next()   #label is useless\n    img = img_batch[0]    \n    \n    ax = axes[i//num_col, i%num_col]\n    ax.imshow(np.array(img))\n\n    ax.set_title('{}--{}'.format(inv_labels[i], img.shape))\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-17T18:14:01.629435Z","iopub.execute_input":"2021-11-17T18:14:01.629759Z","iopub.status.idle":"2021-11-17T18:14:05.111485Z","shell.execute_reply.started":"2021-11-17T18:14:01.62972Z","shell.execute_reply":"2021-11-17T18:14:05.110566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## *examples adaptive thresholding from files*","metadata":{}},{"cell_type":"code","source":"num_row = 2\nnum_col = 7\nfig, axes = plt.subplots(num_row, num_col, figsize=(8*num_row,num_col))\nfor i in range(num_row*num_col):\n  if i < (num_row*num_col):\n    class_dir = os.path.join(training_dir, inv_labels[i])\n#     print(class_dir)\n    class_imgs = next(os.walk(class_dir))[2]\n    class_img = class_imgs[0]\n#     print(os.path.join(class_dir, class_img))\n    #img = Image.open(os.path.join(class_dir, class_img))\n    img = cv.imread(os.path.join(class_dir, class_img),0)\n\n    img = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_MEAN_C,\\\n            cv.THRESH_BINARY,11,2)\n    \n\n    ax = axes[i//num_col, i%num_col]\n    ax.imshow(np.array(img), 'gray')\n    \n    ax.set_title('{}'.format(inv_labels[i]))\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-17T17:46:48.966531Z","iopub.execute_input":"2021-11-17T17:46:48.966902Z","iopub.status.idle":"2021-11-17T17:46:53.821225Z","shell.execute_reply.started":"2021-11-17T17:46:48.966854Z","shell.execute_reply":"2021-11-17T17:46:53.820256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### *example for thresholding*","metadata":{}},{"cell_type":"code","source":"class_dir = os.path.join(training_dir, inv_labels[3])\nclass_imgs = next(os.walk(class_dir))[2]\nclass_img = class_imgs[0]\nimage = Image.open(os.path.join(class_dir, class_img))\n\n# fig2 = plt.figure(figsize=(6, 4))\nplt.imshow(np.uint8(image))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    \n# img = Image.open(os.path.join(class_dir, class_img))\nimg = cv.imread(os.path.join(class_dir, class_img),0)\nret,thresh1 = cv.threshold(img,127,255,cv.THRESH_BINARY)\nret,thresh2 = cv.threshold(img,127,255,cv.THRESH_BINARY_INV)\nret,thresh3 = cv.threshold(img,127,255,cv.THRESH_TRUNC)\nret,thresh4 = cv.threshold(img,127,255,cv.THRESH_TOZERO)\nret,thresh5 = cv.threshold(img,127,255,cv.THRESH_TOZERO_INV)\ntitles = ['Original Image','BINARY','BINARY_INV','TRUNC','TOZERO','TOZERO_INV']\nimages = [img, thresh1, thresh2, thresh3, thresh4, thresh5]\nfor i in range(6):\n    plt.subplot(2,3,i+1),plt.imshow(images[i],'gray',vmin=0,vmax=255)\n    plt.title(titles[i])\n    plt.xticks([]),plt.yticks([])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# img = cv.imread('sudoku.png',0)\nimg = cv.medianBlur(img,5)\nret,th1 = cv.threshold(img,127,255,cv.THRESH_BINARY)\nth2 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_MEAN_C,\\\n            cv.THRESH_BINARY,11,2)\nth3 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n            cv.THRESH_BINARY,11,2)\ntitles = ['Original Image', 'Global Thresholding (v = 127)',\n            'Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']\nimages = [img, th1, th2, th3]\nfor i in range(4):\n    plt.subplot(2,2,i+1),plt.imshow(images[i],'gray')\n    plt.title(titles[i])\n    plt.xticks([]),plt.yticks([])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}